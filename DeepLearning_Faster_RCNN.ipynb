{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_-wv5Td-vCSg",
        "in0oYxpo2OEM"
      ],
      "authorship_tag": "ABX9TyPhQOuOpxxVaiJyStNH4XVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferolver/AirbnbEurope/blob/main/DeepLearning_Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación de una ***Faster R-CNN*** (*Faster Region Convolutional Neural Network*)"
      ],
      "metadata": {
        "id": "WJDs2qWvnR0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura"
      ],
      "metadata": {
        "id": "iDXE95Qqn0Z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La presente implementación se encuentra desarrollada sobre el framework Pytorch, y hace uso del paradigma de ***Transfer Learning***, tomando como base el backbone de una red nauronal tipo ***ResNet-50***."
      ],
      "metadata": {
        "id": "4163O3Tsn3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Componentes requeridos para la presente implementación de ***Faster R-CNN***\n"
      ],
      "metadata": {
        "id": "ABtWJ-0tvpXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. ***Anchor Box Generator***"
      ],
      "metadata": {
        "id": "_-wv5Td-vCSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Las ***Anchor Box*** son un conjunto de cajas delimitadoras predefinidas con una cierta altura y ancho.\n",
        "* Se definen para capturar la escala y la relación de aspecto de clases de objetos específicas a detectar.\n",
        "* Las dimensiones de las ***Anchor Box*** se definen en función de los tamaños de los objetos existentes en el dataset de entrenamiento.\n",
        "* Durante la detección, las ***Anchor Box*** se distribuyen por toda la imagen. La red predice la probabilidad y otros atributos, como el fondo, la intersección sobre la unión (*IoU*) y los desplazamientos para cada ***Anchor Box*** distribuida.\n",
        "* Las predicciones se utilizan para refinar cada ***Anchor Box*** individual.\n",
        "* Se pueden definir ***Anchor Box*** de diferentes dimensiones, cada una para un tamaño de objeto diferente.\n",
        "<div style='height:20px'><br></div>\n",
        "* *Fuente* : Anchor boxes for object detection - *MATLAB & Simulink*. (n.d.). *https://www.mathworks.com/help/vision/ug/anchor-boxes-for-object-detection.html*\n"
      ],
      "metadata": {
        "id": "JMdxT9JWveS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. ***RPN*** (*Region Poposal Network*)"
      ],
      "metadata": {
        "id": "w3SYRHgXvOuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el objetivo de enmarcar regiones de una imagen con presencia de objetos a identificar."
      ],
      "metadata": {
        "id": "juLLzH8EwNoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ***Proposals Generator***"
      ],
      "metadata": {
        "id": "hGAiLyu4wW_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genera propuestas a partir de la salida de la ***RPN***, ordenadas por nivel de confianza, y aplica ***NMS*** (*Non-Maximum Suppression*)."
      ],
      "metadata": {
        "id": "nGBxibaBxGIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. ***RoI Pooling*** (*Region of Interest Pooling*)"
      ],
      "metadata": {
        "id": "in0oYxpo2OEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***RoI Pooling*** (*Region of Interest Pooling*) se utiliza para aprovechar un único mapa de características para todas las propuestas generadas por la ***RPN*** en un solo paso.\n",
        "* Resuelve el problema del requisito de tamaño de imagen fijo para la red de detección de objetos.\n",
        "\n",
        "<img src='https://miro.medium.com/v2/resize:fit:2000/format:webp/1*ftTEVgsx0jfvUSFB6X5mQg.jpeg'/>\n",
        "<div style='font-size: 12px' align='center'>\n",
        "Fuente de la imagen : Xu, J. (2018, November 13). Deep Learning for Object Detection: A Comprehensive review. <i>Medium</i>. <a href=\"https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9\"/>https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9</a>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "* La imagen completa alimenta un modelo de CNN para detectar regiones de Interés (***RoI***) en los mapas de características.\n",
        "* Cada región se separa utilizando una capa de ***RoI Pooling***.\n",
        "\n",
        "* La capa de ***ROI pooling*** toma 2 entradas:\n",
        "  * Un mapa de características obtenido de la CNN después de múltiples capas de convolution y pooling.\n",
        "  * Las ‘N’ propuestas o regiones de interés (***RoI***) que provienen de la ***RPN***.\n",
        "    * Cada propuesta tiene cinco valores: el primero indica el índice y los otros cuatro son las coordenadas de la propuesta.\n",
        "    * Generalmente, esto representa la esquina superior izquierda y la esquina inferior derecha de la propuesta.\n",
        "\n",
        "* ***ROI pooling*** toma cada ***RoI*** de la entrada, selecciona una sección del mapa de entrada que corresponde a ese ***RoI***, y convierte dicha sección en un mapa de dimensiones fijas.\n",
        "\n",
        "\n",
        "* *Fuentes* :\n",
        "  * Girshick, Ross. “Fast r-cnn.” Proceedings of the IEEE International Conference on Computer Vision. 2015. *https://arxiv.org/abs/1504.08083*\n",
        "  * Sambasivarao, K. (2023, October 30). Region of interest pooling - towards data science. *Medium*. *https://towardsdatascience.com/region-of-interest-pooling-f7c637f409af*"
      ],
      "metadata": {
        "id": "QGflCd9I2YNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. ***Faster R-CNN*** (*Faster Region Convolutional Neural Network*)"
      ],
      "metadata": {
        "id": "Sg8UhI6XxHaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapas:\n",
        "\n",
        "* Forward\n",
        "  * Extrae características del backbone:\n",
        "    * El backbone es un modelo pre-entrenado ***ResNet-50***.\n",
        "      * Se removieron las dos últimas capas del modelo pre-entrenado ***ResNet-50***:\n",
        "        * *FC* (fully connected)\n",
        "        * Average Pooling layer.\n",
        "    * Genera regiones propuestas, por medio del modelo ***RPN***.\n",
        "    * Aplica ***RoI Pooling*** (*Region of Interest Pooling*)\n",
        "\n",
        "* Loss Computing\n",
        "\n",
        "* Post-process Detections\n",
        "\n"
      ],
      "metadata": {
        "id": "GWXcep9LxU7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación"
      ],
      "metadata": {
        "id": "iQ1BPW5mpPPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencias"
      ],
      "metadata": {
        "id": "y5rW6Uh2pRlW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuQ3sIIRXZc4"
      },
      "outputs": [],
      "source": [
        "########################################################\n",
        "# Importamos librerías requeridas por la implementación\n",
        "########################################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.ops import RoIPool, nms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación de ***Anchor Box Generator***"
      ],
      "metadata": {
        "id": "IR9s72GVJLVG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Up4kenBSJK9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación de una ***RPN*** (*Region Proposal Network*)"
      ],
      "metadata": {
        "id": "rfpsDM-WpZLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementación de ***Faster R-CNN*** (*Faster Region Convolutional Neural Network*)"
      ],
      "metadata": {
        "id": "fpLMTzwLp0dD"
      }
    }
  ]
}